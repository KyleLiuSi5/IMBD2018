{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Loading the IPython extention autoreload.\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reloading edited module without restarting the kernel.\n",
    "# Referring to https://support.enthought.com/hc/en-us/articles/204469240-Jupyter-IPython-After-editing-a-module-changes-are-not-effective-without-kernel-restart\n",
    "%autoreload\n",
    "\n",
    "from utils import *\n",
    "\n",
    "path_to_train_and_dev = '../../data/first-round/train_and_dev_set'\n",
    "path_to_test = '../../data/first-round/test_set'\n",
    "ratio_of_training_data = 0.8\n",
    "train_set_x, train_set_y, dev_set_x, dev_set_y, test_set_x = load_data(path_to_train_and_dev, ratio_of_training_data, path_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train x: 32 train y 32 dev x: 8 dev y: 8 test x: 10\n"
     ]
    }
   ],
   "source": [
    "print('train x:', len(train_set_x), 'train y', len(train_set_y), 'dev x:', len(\n",
    "    dev_set_x), 'dev y:', len(dev_set_y), 'test x:', len(test_set_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and compiling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_25 (InputLayer)        (None, 7500, 4, 1)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_81 (Batc (None, 7500, 4, 1)        4         \n",
      "_________________________________________________________________\n",
      "conv2d_98 (Conv2D)           (None, 7497, 1, 64)       1088      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_57 (MaxPooling (None, 1874, 1, 64)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_82 (Batc (None, 1874, 1, 64)       256       \n",
      "_________________________________________________________________\n",
      "conv2d_99 (Conv2D)           (None, 1871, 1, 128)      32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_58 (MaxPooling (None, 467, 1, 128)       0         \n",
      "_________________________________________________________________\n",
      "reshape_8 (Reshape)          (None, 467, 128)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_83 (Batc (None, 467, 128)          512       \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "batch_normalization_84 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 134,213\n",
      "Trainable params: 133,571\n",
      "Non-trainable params: 642\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "from model import *\n",
    "\n",
    "# Creating model.\n",
    "model = create_model(input_shape=(train_set_x.shape[1:]), summary=True)\n",
    "\n",
    "# Instantiating the optimizer.\n",
    "opt = Adam()\n",
    "\n",
    "# Determining the loss and metric, and compiling the model.\n",
    "model.compile(optimizer=opt, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading weights, if needed.\n",
    "#model.load_weights(\"./saved_weights/model-019epochs-0.028val_loss.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath=\"./saved_weights/weights-{epoch:003d}epochs-{loss:.3f}loss-{val_loss:.3f}val_loss.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, save_weights_only=True)\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32 samples, validate on 8 samples\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 8s 239ms/step - loss: 0.3322 - val_loss: 0.3253\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 2s 72ms/step - loss: 0.2536 - val_loss: 0.3253\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.2301 - val_loss: 0.3253\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.2119 - val_loss: 0.3253\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.1978 - val_loss: 0.3253\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 2s 71ms/step - loss: 0.1944 - val_loss: 0.3253\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.1924 - val_loss: 0.3253\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 2s 73ms/step - loss: 0.1892 - val_loss: 0.3253\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 2s 70ms/step - loss: 0.1801 - val_loss: 0.3253\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 3s 84ms/step - loss: 0.1709 - val_loss: 0.3253\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.1633 - val_loss: 0.3253\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 3s 92ms/step - loss: 0.1593 - val_loss: 0.3253\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 3s 92ms/step - loss: 0.1587 - val_loss: 0.3253\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.1590 - val_loss: 0.3253\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.1587 - val_loss: 0.3253\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 3s 82ms/step - loss: 0.1558 - val_loss: 0.3253\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 3s 81ms/step - loss: 0.1520 - val_loss: 0.3253\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.1474 - val_loss: 0.3253\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 3s 81ms/step - loss: 0.1435 - val_loss: 0.3253\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.1410 - val_loss: 0.3253\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.1387 - val_loss: 0.3253\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.1365 - val_loss: 0.3253\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.1335 - val_loss: 0.3253\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 2s 70ms/step - loss: 0.1311 - val_loss: 0.3253\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 2s 72ms/step - loss: 0.1281 - val_loss: 0.3253\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 2s 73ms/step - loss: 0.1246 - val_loss: 0.3253\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 2s 70ms/step - loss: 0.1213 - val_loss: 0.3253\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 2s 72ms/step - loss: 0.1181 - val_loss: 0.3253\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 2s 72ms/step - loss: 0.1158 - val_loss: 0.3253\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 2s 71ms/step - loss: 0.1142 - val_loss: 0.3253\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 2s 72ms/step - loss: 0.1123 - val_loss: 0.3253\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.1110 - val_loss: 0.3253\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 2s 73ms/step - loss: 0.1103 - val_loss: 0.3253\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 2s 71ms/step - loss: 0.1095 - val_loss: 0.3253\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 2s 71ms/step - loss: 0.1090 - val_loss: 0.3253\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 2s 73ms/step - loss: 0.1088 - val_loss: 0.3253\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 3s 84ms/step - loss: 0.1084 - val_loss: 0.3253\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 3s 84ms/step - loss: 0.1073 - val_loss: 0.3253\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.1061 - val_loss: 0.3253\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.1049 - val_loss: 0.3253\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 2s 73ms/step - loss: 0.1040 - val_loss: 0.3253\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.1035 - val_loss: 0.3253\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 2s 71ms/step - loss: 0.1031 - val_loss: 0.3253\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 2s 71ms/step - loss: 0.1026 - val_loss: 0.3253\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 2s 67ms/step - loss: 0.1016 - val_loss: 0.3253\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 2s 70ms/step - loss: 0.1005 - val_loss: 0.3253\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 2s 70ms/step - loss: 0.0995 - val_loss: 0.3253\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 2s 70ms/step - loss: 0.0985 - val_loss: 0.3253\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 2s 71ms/step - loss: 0.0975 - val_loss: 0.3253\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 2s 70ms/step - loss: 0.0967 - val_loss: 0.3253\n"
     ]
    }
   ],
   "source": [
    "History_fit = model.fit(train_set_x, train_set_y, batch_size=train_set_x.shape[0], epochs=50, callbacks=callbacks_list, validation_data=(dev_set_x, dev_set_y))\n",
    "history_fit = History_fit.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving history\n",
    "#import pickle\n",
    "#with open('./trainHistoryDict', 'wb') as file_pi:\n",
    "#    pickle.dump(history_fit, file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the training and dev losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./trainHistoryDict', 'rb') as file_pi:\n",
    "    history_fit = pickle.load(file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating and printing root mean square error of fitting\n",
    "import numpy as np\n",
    "rms_train_w_dp_all = np.sqrt(history_fit['loss'])\n",
    "rms_dev_all = np.sqrt(history_fit['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(rms_train_w_dp_all)\n",
    "plt.plot(rms_dev_all)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'dev'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the best epoch.\n",
    "min_epoch = np.argmin(rms_dev_all)\n",
    "print('Lowest loss of dev set occurs at epoch of', min_epoch)\n",
    "\n",
    "# Loading the corresponding model.\n",
    "model.load_weights(\"./saved_weights/weights-019epochs-0.093loss-0.029val_loss.h5\")\n",
    "\n",
    "# Evaluating training set without dropout layer.\n",
    "ms_train_wo_dp_best = model.evaluate(x=train_set_x, y=train_set_y, batch_size=train_set_x.shape[0])\n",
    "rms_train_wo_dp_best = np.sqrt(ms_train_wo_dp_best)\n",
    "\n",
    "print('RMS error of training set of the best fitting:', rms_train_wo_dp_best)\n",
    "print('RMS error of dev set of the best fitting:', rms_dev_all[min_epoch])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(x=test_set_x)\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
