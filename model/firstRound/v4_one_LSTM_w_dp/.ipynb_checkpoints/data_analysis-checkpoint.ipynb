{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the IPython extention autoreload.\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reloading edited module without restarting the kernel.\n",
    "# Referring to https://support.enthought.com/hc/en-us/articles/204469240-Jupyter-IPython-After-editing-a-module-changes-are-not-effective-without-kernel-restart\n",
    "%autoreload\n",
    "\n",
    "from utils import *\n",
    "\n",
    "path_to_train_and_dev = '../../data/first-round/train_and_dev_set'\n",
    "path_to_test = '../../data/first-round/test_set'\n",
    "ratio_of_training_data = 0.8\n",
    "train_set_x, train_set_y, dev_set_x, dev_set_y, test_set_x = load_data(path_to_train_and_dev, ratio_of_training_data, path_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train x: 32 train y 32 dev x: 8 dev y: 8 test x: 10\n"
     ]
    }
   ],
   "source": [
    "print('train x:', len(train_set_x), 'train y', len(train_set_y), 'dev x:', len(\n",
    "    dev_set_x), 'dev y:', len(dev_set_y), 'test x:', len(test_set_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and compiling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 7500, 4)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 7500, 4)           16        \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               136192    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 137,489\n",
      "Trainable params: 136,969\n",
      "Non-trainable params: 520\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "from model import *\n",
    "\n",
    "# Creating model.\n",
    "model = create_model(input_shape=(train_set_x.shape[1:]), summary=True)\n",
    "\n",
    "# Instantiating the optimizer.\n",
    "opt = Adam()\n",
    "\n",
    "# Determining the loss and metric, and compiling the model.\n",
    "model.compile(optimizer=opt, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading weights, if needed.\n",
    "#model.load_weights(\"./saved_weights/model-019epochs-0.028val_loss.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath=\"./saved_weights/weights-{epoch:003d}epochs-{loss:.3f}loss-{val_loss:.3f}val_loss.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, save_weights_only=True)\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32 samples, validate on 8 samples\n",
      "Epoch 1/20\n",
      "32/32 [==============================] - 27s 855ms/step - loss: 0.4003 - val_loss: 0.2769\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 24s 746ms/step - loss: 0.3822 - val_loss: 0.2600\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 24s 744ms/step - loss: 0.3625 - val_loss: 0.2586\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 26s 802ms/step - loss: 0.3440 - val_loss: 0.2544\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 24s 765ms/step - loss: 0.3203 - val_loss: 0.2556\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 24s 744ms/step - loss: 0.2979 - val_loss: 0.2727\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 24s 743ms/step - loss: 0.2755 - val_loss: 0.2817\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 24s 749ms/step - loss: 0.2536 - val_loss: 0.3004\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 24s 743ms/step - loss: 0.2357 - val_loss: 0.3119\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 24s 745ms/step - loss: 0.2119 - val_loss: 0.3056\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 24s 743ms/step - loss: 0.1972 - val_loss: 0.3136\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 24s 746ms/step - loss: 0.1755 - val_loss: 0.3230\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 26s 803ms/step - loss: 0.1572 - val_loss: 0.3253\n",
      "Epoch 14/20\n",
      "32/32 [==============================] - 24s 742ms/step - loss: 0.1417 - val_loss: 0.3253\n",
      "Epoch 15/20\n",
      "32/32 [==============================] - 25s 796ms/step - loss: 0.1287 - val_loss: 0.3253\n",
      "Epoch 16/20\n",
      "32/32 [==============================] - 25s 784ms/step - loss: 0.1113 - val_loss: 0.3253\n",
      "Epoch 17/20\n",
      "32/32 [==============================] - 26s 805ms/step - loss: 0.0975 - val_loss: 0.3253\n",
      "Epoch 18/20\n",
      "32/32 [==============================] - 26s 798ms/step - loss: 0.0860 - val_loss: 0.3253\n",
      "Epoch 19/20\n",
      "32/32 [==============================] - 24s 744ms/step - loss: 0.0742 - val_loss: 0.3253\n",
      "Epoch 20/20\n",
      "32/32 [==============================] - 24s 750ms/step - loss: 0.0651 - val_loss: 0.3147\n"
     ]
    }
   ],
   "source": [
    "History_fit = model.fit(train_set_x, train_set_y, batch_size=train_set_x.shape[0], epochs=20, callbacks=callbacks_list, validation_data=(dev_set_x, dev_set_y))\n",
    "history_fit = History_fit.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving history\n",
    "import pickle\n",
    "with open('./trainHistoryDict', 'wb') as file_pi:\n",
    "    pickle.dump(history_fit, file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the training and dev losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#with open('./trainHistoryDict', 'rb') as file_pi:\n",
    "#    history_fit = pickle.load(file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating and printing root mean square error of fitting\n",
    "rms_train = np.sqrt(history_fit['loss'])\n",
    "rms_dev = np.sqrt(history_fit['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(rms_train)\n",
    "plt.plot(rms_dev)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'dev'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the best epoch\n",
    "#print('RMS error of fitting:', rms_error_fit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
